{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting stories for the challenge: two_supporting_facts_10k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ekremguzelyel/anaconda/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Vocab size: 36 unique words\n",
      "Story max length: 552 words\n",
      "Query max length: 5 words\n",
      "Number of training stories: 10000\n",
      "Number of test stories: 1000\n",
      "-\n",
      "Here's what a \"story\" tuple looks like (input, query, answer):\n",
      "(['Mary', 'moved', 'to', 'the', 'bathroom', '.', 'Sandra', 'journeyed', 'to', 'the', 'bedroom', '.', 'Mary', 'got', 'the', 'football', 'there', '.', 'John', 'went', 'to', 'the', 'kitchen', '.', 'Mary', 'went', 'back', 'to', 'the', 'kitchen', '.', 'Mary', 'went', 'back', 'to', 'the', 'garden', '.'], ['Where', 'is', 'the', 'football', '?'], 'garden')\n",
      "-\n",
      "Vectorizing the word sequences...\n",
      "-\n",
      "inputs: integer tensor of shape (samples, max_length)\n",
      "inputs_train shape: (10000, 552)\n",
      "inputs_test shape: (1000, 552)\n",
      "-\n",
      "queries: integer tensor of shape (samples, max_length)\n",
      "queries_train shape: (10000, 5)\n",
      "queries_test shape: (1000, 5)\n",
      "-\n",
      "answers: binary (1 or 0) tensor of shape (samples, vocab_size)\n",
      "answers_train shape: (10000,)\n",
      "answers_test shape: (1000,)\n",
      "-\n",
      "Compiling...\n",
      "0\n",
      "input_sequence (?, 552)\n",
      "question (?, 5)\n",
      "input_encoded_m (?, 552, 64)\n",
      "input_encoded_c (?, 552, 5)\n",
      "question_encoded (?, 5, 64)\n",
      "match (?, 552, 5)\n",
      "response (?, 5, 552)\n",
      "answer (?, 5, 616)\n",
      "final (?, 5, 616)\n",
      "1\n",
      "input_sequence (?, 552)\n",
      "question (?, 5)\n",
      "input_encoded_m (?, 552, 64)\n",
      "input_encoded_c (?, 552, 5)\n",
      "question_encoded (?, 5, 64)\n",
      "match (?, 552, 5)\n",
      "response (?, 5, 552)\n",
      "answer (?, 5, 616)\n",
      "final (?, 5, 616)\n",
      "2\n",
      "input_sequence (?, 552)\n",
      "question (?, 5)\n",
      "input_encoded_m (?, 552, 64)\n",
      "input_encoded_c (?, 552, 5)\n",
      "question_encoded (?, 5, 64)\n",
      "match (?, 552, 5)\n",
      "response (?, 5, 552)\n",
      "answer (?, 5, 616)\n",
      "final (?, 5, 616)\n",
      "(?, 5, 64)\n",
      "(?, 32)\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "10000/10000 [==============================] - 25s 3ms/step - loss: 1.9754 - acc: 0.1695 - val_loss: 1.8500 - val_acc: 0.1460\n",
      "Epoch 2/120\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 1.8221 - acc: 0.1721 - val_loss: 1.8078 - val_acc: 0.1370\n",
      "Epoch 3/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 1.8006 - acc: 0.1755 - val_loss: 1.7885 - val_acc: 0.1700\n",
      "Epoch 4/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 1.7760 - acc: 0.2011 - val_loss: 1.7556 - val_acc: 0.2070\n",
      "Epoch 5/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 1.7400 - acc: 0.2261 - val_loss: 1.7232 - val_acc: 0.2390\n",
      "Epoch 6/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 1.7176 - acc: 0.2554 - val_loss: 1.7029 - val_acc: 0.2550\n",
      "Epoch 7/120\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 1.6957 - acc: 0.2758 - val_loss: 1.6780 - val_acc: 0.2630\n",
      "Epoch 8/120\n",
      "10000/10000 [==============================] - 25s 3ms/step - loss: 1.6706 - acc: 0.3003 - val_loss: 1.6616 - val_acc: 0.2710\n",
      "Epoch 9/120\n",
      "10000/10000 [==============================] - 26s 3ms/step - loss: 1.6507 - acc: 0.3079 - val_loss: 1.6601 - val_acc: 0.2750\n",
      "Epoch 10/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 1.6373 - acc: 0.3128 - val_loss: 1.6757 - val_acc: 0.2790\n",
      "Epoch 11/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 1.6180 - acc: 0.3309 - val_loss: 1.6584 - val_acc: 0.2930\n",
      "Epoch 12/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 1.5979 - acc: 0.3436 - val_loss: 1.6487 - val_acc: 0.2960\n",
      "Epoch 13/120\n",
      "10000/10000 [==============================] - 25s 2ms/step - loss: 1.5773 - acc: 0.3619 - val_loss: 1.6402 - val_acc: 0.3090\n",
      "Epoch 14/120\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.5491 - acc: 0.3719 - val_loss: 1.6213 - val_acc: 0.3230\n",
      "Epoch 15/120\n",
      "10000/10000 [==============================] - 26s 3ms/step - loss: 1.5285 - acc: 0.3924 - val_loss: 1.6047 - val_acc: 0.3400\n",
      "Epoch 16/120\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 1.4988 - acc: 0.4099 - val_loss: 1.5888 - val_acc: 0.3540\n",
      "Epoch 17/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 1.4898 - acc: 0.4088 - val_loss: 1.5883 - val_acc: 0.3640\n",
      "Epoch 18/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 1.4640 - acc: 0.4258 - val_loss: 1.6044 - val_acc: 0.3480\n",
      "Epoch 19/120\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.4480 - acc: 0.4330 - val_loss: 1.6044 - val_acc: 0.3460\n",
      "Epoch 20/120\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.4436 - acc: 0.4362 - val_loss: 1.5943 - val_acc: 0.3610\n",
      "Epoch 21/120\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 1.4127 - acc: 0.4441 - val_loss: 1.6036 - val_acc: 0.3560\n",
      "Epoch 22/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 1.4047 - acc: 0.4539 - val_loss: 1.5958 - val_acc: 0.3620\n",
      "Epoch 23/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 1.3809 - acc: 0.4625 - val_loss: 1.6075 - val_acc: 0.3700\n",
      "Epoch 24/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 1.3646 - acc: 0.4721 - val_loss: 1.6102 - val_acc: 0.3590\n",
      "Epoch 25/120\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.3546 - acc: 0.4724 - val_loss: 1.6080 - val_acc: 0.3660\n",
      "Epoch 26/120\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.3319 - acc: 0.4913 - val_loss: 1.6183 - val_acc: 0.3660\n",
      "Epoch 27/120\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 1.3100 - acc: 0.4997 - val_loss: 1.6224 - val_acc: 0.3670\n",
      "Epoch 28/120\n",
      "10000/10000 [==============================] - 21s 2ms/step - loss: 1.3069 - acc: 0.4946 - val_loss: 1.6412 - val_acc: 0.3520\n",
      "Epoch 29/120\n",
      "10000/10000 [==============================] - 19s 2ms/step - loss: 1.2830 - acc: 0.5043 - val_loss: 1.6459 - val_acc: 0.3600\n",
      "Epoch 30/120\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 1.2814 - acc: 0.5025 - val_loss: 1.6314 - val_acc: 0.3650\n",
      "Epoch 31/120\n",
      "10000/10000 [==============================] - 24s 2ms/step - loss: 1.2653 - acc: 0.5169 - val_loss: 1.6395 - val_acc: 0.3480\n",
      "Epoch 32/120\n",
      "10000/10000 [==============================] - 24s 2ms/step - loss: 1.2527 - acc: 0.5212 - val_loss: 1.6399 - val_acc: 0.3580\n",
      "Epoch 33/120\n",
      "10000/10000 [==============================] - 27s 3ms/step - loss: 1.2403 - acc: 0.5223 - val_loss: 1.6602 - val_acc: 0.3570\n",
      "Epoch 34/120\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 1.2273 - acc: 0.5294 - val_loss: 1.6741 - val_acc: 0.3490\n",
      "Epoch 35/120\n",
      "10000/10000 [==============================] - 24s 2ms/step - loss: 1.2212 - acc: 0.5336 - val_loss: 1.6835 - val_acc: 0.3480\n",
      "Epoch 36/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 1.2099 - acc: 0.5347 - val_loss: 1.6836 - val_acc: 0.3520\n",
      "Epoch 37/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 1.1930 - acc: 0.5422 - val_loss: 1.6962 - val_acc: 0.3410\n",
      "Epoch 38/120\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 1.1981 - acc: 0.5379 - val_loss: 1.7053 - val_acc: 0.3420\n",
      "Epoch 39/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 1.1709 - acc: 0.5550 - val_loss: 1.6956 - val_acc: 0.3500\n",
      "Epoch 40/120\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 1.1748 - acc: 0.5529 - val_loss: 1.7029 - val_acc: 0.3570\n",
      "Epoch 41/120\n",
      "10000/10000 [==============================] - 26s 3ms/step - loss: 1.1561 - acc: 0.5627 - val_loss: 1.7312 - val_acc: 0.3440\n",
      "Epoch 42/120\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 1.1525 - acc: 0.5628 - val_loss: 1.7297 - val_acc: 0.3400\n",
      "Epoch 43/120\n",
      "10000/10000 [==============================] - 24s 2ms/step - loss: 1.1347 - acc: 0.5679 - val_loss: 1.7342 - val_acc: 0.3440\n",
      "Epoch 44/120\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 1.1271 - acc: 0.5758 - val_loss: 1.7479 - val_acc: 0.3430\n",
      "Epoch 45/120\n",
      "10000/10000 [==============================] - 23s 2ms/step - loss: 1.1283 - acc: 0.5743 - val_loss: 1.7575 - val_acc: 0.3500\n",
      "Epoch 46/120\n",
      "10000/10000 [==============================] - 22s 2ms/step - loss: 1.1051 - acc: 0.5879 - val_loss: 1.7526 - val_acc: 0.3450\n",
      "Epoch 47/120\n",
      " 8832/10000 [=========================>....] - ETA: 2s - loss: 1.0991 - acc: 0.5834- ETA: 2s - loss: 1.0990 - acc"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Trains a memory network on the bAbI dataset.\n",
    "References:\n",
    "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
    "  [\"Towards AI-Complete Question Answering:\n",
    "  A Set of Prerequisite Toy Tasks\"](http://arxiv.org/abs/1502.05698)\n",
    "- Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
    "  [\"End-To-End Memory Networks\"](http://arxiv.org/abs/1503.08895)\n",
    "Reaches 98.6% accuracy on task 'single_supporting_fact_10k' after 120 epochs.\n",
    "Time per epoch: 3s on CPU (core i7).\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from functools import reduce\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "def tokenize(sent):\n",
    "    '''Return the tokens of a sentence including punctuation.\n",
    "    >>> tokenize('Bob dropped the apple. Where is the apple?')\n",
    "    ['Bob', 'dropped', 'the', 'apple', '.', 'Where', 'is', 'the', 'apple', '?']\n",
    "    '''\n",
    "    return [x.strip() for x in re.split(r'(\\W+)?', sent) if x.strip()]\n",
    "\n",
    "\n",
    "def parse_stories(lines, only_supporting=False):\n",
    "    '''Parse stories provided in the bAbi tasks format\n",
    "    If only_supporting is true, only the sentences\n",
    "    that support the answer are kept.\n",
    "    '''\n",
    "    data = []\n",
    "    story = []\n",
    "    for line in lines:\n",
    "        line = line.decode('utf-8').strip()\n",
    "        nid, line = line.split(' ', 1)\n",
    "        nid = int(nid)\n",
    "        if nid == 1:\n",
    "            story = []\n",
    "        if '\\t' in line:\n",
    "            q, a, supporting = line.split('\\t')\n",
    "            q = tokenize(q)\n",
    "            if only_supporting:\n",
    "                # Only select the related substory\n",
    "                supporting = map(int, supporting.split())\n",
    "                substory = [story[i - 1] for i in supporting]\n",
    "            else:\n",
    "                # Provide all the substories\n",
    "                substory = [x for x in story if x]\n",
    "            data.append((substory, q, a))\n",
    "            story.append('')\n",
    "        else:\n",
    "            sent = tokenize(line)\n",
    "            story.append(sent)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_stories(f, only_supporting=False, max_length=None):\n",
    "    '''Given a file name, read the file,\n",
    "    retrieve the stories,\n",
    "    and then convert the sentences into a single story.\n",
    "    If max_length is supplied,\n",
    "    any stories longer than max_length tokens will be discarded.\n",
    "    '''\n",
    "    data = parse_stories(f.readlines(), only_supporting=only_supporting)\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "    data = [(flatten(story), q, answer) for story, q, answer in data\n",
    "            if not max_length or len(flatten(story)) < max_length]\n",
    "    return data\n",
    "\n",
    "\n",
    "def vectorize_stories(data):\n",
    "    inputs, queries, answers = [], [], []\n",
    "    for story, query, answer in data:\n",
    "        inputs.append([word_idx[w] for w in story])\n",
    "        queries.append([word_idx[w] for w in query])\n",
    "        answers.append(word_idx[answer])\n",
    "    return (pad_sequences(inputs, maxlen=story_maxlen),\n",
    "            pad_sequences(queries, maxlen=query_maxlen),\n",
    "            np.array(answers))\n",
    "\n",
    "try:\n",
    "    path = get_file('babi-tasks-v1-2.tar.gz',\n",
    "                    origin='https://s3.amazonaws.com/text-datasets/'\n",
    "                           'babi_tasks_1-20_v1-2.tar.gz')\n",
    "except:\n",
    "    print('Error downloading dataset, please download it manually:\\n'\n",
    "          '$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2'\n",
    "          '.tar.gz\\n'\n",
    "          '$ mv tasks_1-20_v1-2.tar.gz ~/.keras/datasets/babi-tasks-v1-2.tar.gz')\n",
    "    raise\n",
    "\n",
    "\n",
    "challenges = {\n",
    "    # QA1 with 10,000 samples\n",
    "    'single_supporting_fact_10k': 'tasks_1-20_v1-2/en-10k/qa1_'\n",
    "                                  'single-supporting-fact_{}.txt',\n",
    "    # QA2 with 10,000 samples\n",
    "    'two_supporting_facts_10k': 'tasks_1-20_v1-2/en-10k/qa2_'\n",
    "                                'two-supporting-facts_{}.txt',\n",
    "}\n",
    "challenge_type = 'two_supporting_facts_10k'\n",
    "challenge = challenges[challenge_type]\n",
    "\n",
    "print('Extracting stories for the challenge:', challenge_type)\n",
    "with tarfile.open(path) as tar:\n",
    "    train_stories = get_stories(tar.extractfile(challenge.format('train')))\n",
    "    test_stories = get_stories(tar.extractfile(challenge.format('test')))\n",
    "\n",
    "vocab = set()\n",
    "for story, q, answer in train_stories + test_stories:\n",
    "    vocab |= set(story + q + [answer])\n",
    "vocab = sorted(vocab)\n",
    "\n",
    "# Reserve 0 for masking via pad_sequences\n",
    "vocab_size = len(vocab) + 1\n",
    "story_maxlen = max(map(len, (x for x, _, _ in train_stories + test_stories)))\n",
    "query_maxlen = max(map(len, (x for _, x, _ in train_stories + test_stories)))\n",
    "\n",
    "print('-')\n",
    "print('Vocab size:', vocab_size, 'unique words')\n",
    "print('Story max length:', story_maxlen, 'words')\n",
    "print('Query max length:', query_maxlen, 'words')\n",
    "print('Number of training stories:', len(train_stories))\n",
    "print('Number of test stories:', len(test_stories))\n",
    "print('-')\n",
    "print('Here\\'s what a \"story\" tuple looks like (input, query, answer):')\n",
    "print(train_stories[0])\n",
    "print('-')\n",
    "print('Vectorizing the word sequences...')\n",
    "\n",
    "word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n",
    "inputs_train, queries_train, answers_train = vectorize_stories(train_stories)\n",
    "inputs_test, queries_test, answers_test = vectorize_stories(test_stories)\n",
    "\n",
    "print('-')\n",
    "print('inputs: integer tensor of shape (samples, max_length)')\n",
    "print('inputs_train shape:', inputs_train.shape)\n",
    "print('inputs_test shape:', inputs_test.shape)\n",
    "print('-')\n",
    "print('queries: integer tensor of shape (samples, max_length)')\n",
    "print('queries_train shape:', queries_train.shape)\n",
    "print('queries_test shape:', queries_test.shape)\n",
    "print('-')\n",
    "print('answers: binary (1 or 0) tensor of shape (samples, vocab_size)')\n",
    "print('answers_train shape:', answers_train.shape)\n",
    "print('answers_test shape:', answers_test.shape)\n",
    "print('-')\n",
    "print('Compiling...')\n",
    "\n",
    "# placeholders\n",
    "input_sequence = Input((story_maxlen,))\n",
    "question = Input((query_maxlen,))\n",
    "\n",
    "\n",
    "\n",
    "# encoders\n",
    "# embed the input sequence into a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, embedding_dim)\n",
    "\n",
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=query_maxlen))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)\n",
    "\n",
    "question_encoder = Sequential()\n",
    "# question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "#                                output_dim=64, \n",
    "#                                input_length=query_maxlen))\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64))\n",
    "\n",
    "question_encoder.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "input_encoded_m = input_encoder_m(inputs=input_sequence) # Meaning that \"inputs = input_sequence\"\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "\n",
    "question_encoded = question_encoder(question)\n",
    "\n",
    "num_hops=3\n",
    "for i in range(num_hops):\n",
    "    print(i)\n",
    "    \n",
    "    # embed the question into a sequence of vectors\n",
    "    \n",
    "    \n",
    "    # output: (samples, query_maxlen, embedding_dim)\n",
    "\n",
    "    # encode input sequence and questions (which are indices)\n",
    "    # to sequences of dense vectors\n",
    "    \n",
    "    \n",
    "    #DEBUG\n",
    "    print(\"input_sequence\", input_sequence.get_shape())\n",
    "    print(\"question\", question.get_shape())\n",
    "    print(\"input_encoded_m\", input_encoded_m.get_shape())\n",
    "    print(\"input_encoded_c\", input_encoded_c.get_shape())\n",
    "    print(\"question_encoded\", question_encoded.get_shape())\n",
    "    \n",
    "    \n",
    "    # compute a 'match' between the first input vector sequence\n",
    "    # and the question vector sequence\n",
    "    # shape: `(samples, story_maxlen, query_maxlen)`\n",
    "    match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "    match = Activation('softmax')(match)\n",
    "    print(\"match\", match.get_shape())\n",
    "    \n",
    "    # add the match matrix with the second input vector sequence\n",
    "    response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "    response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)\n",
    "    print(\"response\", response.get_shape())\n",
    "#     print(response.get_shape())\n",
    "#     question = response\n",
    "#     question_decoder # IMPLEMENT THIS\n",
    "#     input_sequence = response\n",
    "#     question_encoded = dot([response, question_encoded], axes=-1)\n",
    "    \n",
    "    \n",
    "    answer = concatenate([response, question_encoded])\n",
    "    print(\"answer\", answer.get_shape())\n",
    "    if i==0:\n",
    "        final_ans = answer\n",
    "    else:\n",
    "        final_ans = add([final_ans, answer])\n",
    "    print(\"final\", final_ans.get_shape())\n",
    "print(question_encoded.get_shape())\n",
    "# concatenate the match matrix with the question vector sequence\n",
    "# answer = add([response, question_encoded])\n",
    "\n",
    "# print(\"answer\", answer.get_shape())\n",
    "\n",
    "\n",
    "# the original paper uses a matrix multiplication for this reduction step.\n",
    "# we choose to use a RNN instead.\n",
    "# answer = LSTM(32, return_sequences=True)(answer)  # (samples, 32)\n",
    "\n",
    "# # one regularization layer -- more would probably be needed.\n",
    "# answer = Dropout(0.3)(answer)\n",
    "final_ans = LSTM(32)(final_ans)\n",
    "final_ans = Dropout(0.3)(final_ans)\n",
    "print(final_ans.get_shape())\n",
    "final_ans = Dense(vocab_size)(final_ans)  # (samples, vocab_size)\n",
    "\n",
    "#     input_sequence = response\n",
    "\n",
    "    \n",
    "# we output a probability distribution over the vocabulary\n",
    "final_ans = Activation('softmax')(final_ans)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], final_ans)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "model.fit([inputs_train, queries_train], answers_train,\n",
    "          batch_size=32,\n",
    "          epochs=120,\n",
    "          validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.evaluate(test_stories, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrPAPiwxZjyCrILQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "plt.plot(model.history.history['acc'])\n",
    "plt.plot(model.history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"lstm32hops3.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
