{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting stories for the challenge: two_supporting_facts_10k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ekremguzelyel/anaconda/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Vocab size: 36 unique words\n",
      "Story max length: 552 words\n",
      "Query max length: 5 words\n",
      "Number of training stories: 10000\n",
      "Number of test stories: 1000\n",
      "-\n",
      "Here's what a \"story\" tuple looks like (input, query, answer):\n",
      "(['Mary', 'moved', 'to', 'the', 'bathroom', '.', 'Sandra', 'journeyed', 'to', 'the', 'bedroom', '.', 'Mary', 'got', 'the', 'football', 'there', '.', 'John', 'went', 'to', 'the', 'kitchen', '.', 'Mary', 'went', 'back', 'to', 'the', 'kitchen', '.', 'Mary', 'went', 'back', 'to', 'the', 'garden', '.'], ['Where', 'is', 'the', 'football', '?'], 'garden')\n",
      "-\n",
      "Vectorizing the word sequences...\n",
      "-\n",
      "inputs: integer tensor of shape (samples, max_length)\n",
      "inputs_train shape: (10000, 552)\n",
      "inputs_test shape: (1000, 552)\n",
      "-\n",
      "queries: integer tensor of shape (samples, max_length)\n",
      "queries_train shape: (10000, 5)\n",
      "queries_test shape: (1000, 5)\n",
      "-\n",
      "answers: binary (1 or 0) tensor of shape (samples, vocab_size)\n",
      "answers_train shape: (10000,)\n",
      "answers_test shape: (1000,)\n",
      "-\n",
      "Compiling...\n",
      "0\n",
      "input_sequence (?, 552)\n",
      "question (?, 5)\n",
      "input_encoded (?, 552, 64)\n",
      "question_encoded (?, 5, 64)\n",
      "1\n",
      "input_sequence (?, 5, 552)\n",
      "question (?, 5, 64)\n",
      "input_encoded (?, 5, 552, 64)\n",
      "question_encoded (?, 5, 64, 64)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimension incompatibility 552 != 64. Layer shapes: (None, 5, 552, 64), (None, 5, 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-8dcb64cc9df6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;31m# and the question vector sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;31m# shape: `(samples, story_maxlen, query_maxlen)`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_encoded_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_encoded\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ekremguzelyel/anaconda/lib/python3.6/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(inputs, axes, normalize, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdot\u001b[0m \u001b[0mproduct\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \"\"\"\n\u001b[0;32m--> 660\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ekremguzelyel/anaconda/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ekremguzelyel/anaconda/lib/python3.6/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    461\u001b[0m                 \u001b[0;34m'Dimension incompatibility '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0;34m'%s != %s. '\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mshape1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m                 'Layer shapes: %s, %s' % (shape1, shape2))\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimension incompatibility 552 != 64. Layer shapes: (None, 5, 552, 64), (None, 5, 64)"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Trains a memory network on the bAbI dataset.\n",
    "References:\n",
    "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
    "  [\"Towards AI-Complete Question Answering:\n",
    "  A Set of Prerequisite Toy Tasks\"](http://arxiv.org/abs/1502.05698)\n",
    "- Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
    "  [\"End-To-End Memory Networks\"](http://arxiv.org/abs/1503.08895)\n",
    "Reaches 98.6% accuracy on task 'single_supporting_fact_10k' after 120 epochs.\n",
    "Time per epoch: 3s on CPU (core i7).\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from functools import reduce\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "def tokenize(sent):\n",
    "    '''Return the tokens of a sentence including punctuation.\n",
    "    >>> tokenize('Bob dropped the apple. Where is the apple?')\n",
    "    ['Bob', 'dropped', 'the', 'apple', '.', 'Where', 'is', 'the', 'apple', '?']\n",
    "    '''\n",
    "    return [x.strip() for x in re.split(r'(\\W+)?', sent) if x.strip()]\n",
    "\n",
    "\n",
    "def parse_stories(lines, only_supporting=False):\n",
    "    '''Parse stories provided in the bAbi tasks format\n",
    "    If only_supporting is true, only the sentences\n",
    "    that support the answer are kept.\n",
    "    '''\n",
    "    data = []\n",
    "    story = []\n",
    "    for line in lines:\n",
    "        line = line.decode('utf-8').strip()\n",
    "        nid, line = line.split(' ', 1)\n",
    "        nid = int(nid)\n",
    "        if nid == 1:\n",
    "            story = []\n",
    "        if '\\t' in line:\n",
    "            q, a, supporting = line.split('\\t')\n",
    "            q = tokenize(q)\n",
    "            if only_supporting:\n",
    "                # Only select the related substory\n",
    "                supporting = map(int, supporting.split())\n",
    "                substory = [story[i - 1] for i in supporting]\n",
    "            else:\n",
    "                # Provide all the substories\n",
    "                substory = [x for x in story if x]\n",
    "            data.append((substory, q, a))\n",
    "            story.append('')\n",
    "        else:\n",
    "            sent = tokenize(line)\n",
    "            story.append(sent)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_stories(f, only_supporting=False, max_length=None):\n",
    "    '''Given a file name, read the file,\n",
    "    retrieve the stories,\n",
    "    and then convert the sentences into a single story.\n",
    "    If max_length is supplied,\n",
    "    any stories longer than max_length tokens will be discarded.\n",
    "    '''\n",
    "    data = parse_stories(f.readlines(), only_supporting=only_supporting)\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "    data = [(flatten(story), q, answer) for story, q, answer in data\n",
    "            if not max_length or len(flatten(story)) < max_length]\n",
    "    return data\n",
    "\n",
    "\n",
    "def vectorize_stories(data):\n",
    "    inputs, queries, answers = [], [], []\n",
    "    for story, query, answer in data:\n",
    "        inputs.append([word_idx[w] for w in story])\n",
    "        queries.append([word_idx[w] for w in query])\n",
    "        answers.append(word_idx[answer])\n",
    "    return (pad_sequences(inputs, maxlen=story_maxlen),\n",
    "            pad_sequences(queries, maxlen=query_maxlen),\n",
    "            np.array(answers))\n",
    "\n",
    "try:\n",
    "    path = get_file('babi-tasks-v1-2.tar.gz',\n",
    "                    origin='https://s3.amazonaws.com/text-datasets/'\n",
    "                           'babi_tasks_1-20_v1-2.tar.gz')\n",
    "except:\n",
    "    print('Error downloading dataset, please download it manually:\\n'\n",
    "          '$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2'\n",
    "          '.tar.gz\\n'\n",
    "          '$ mv tasks_1-20_v1-2.tar.gz ~/.keras/datasets/babi-tasks-v1-2.tar.gz')\n",
    "    raise\n",
    "\n",
    "\n",
    "challenges = {\n",
    "    # QA1 with 10,000 samples\n",
    "    'single_supporting_fact_10k': 'tasks_1-20_v1-2/en-10k/qa1_'\n",
    "                                  'single-supporting-fact_{}.txt',\n",
    "    # QA2 with 10,000 samples\n",
    "    'two_supporting_facts_10k': 'tasks_1-20_v1-2/en-10k/qa2_'\n",
    "                                'two-supporting-facts_{}.txt',\n",
    "}\n",
    "challenge_type = 'two_supporting_facts_10k'\n",
    "challenge = challenges[challenge_type]\n",
    "\n",
    "print('Extracting stories for the challenge:', challenge_type)\n",
    "with tarfile.open(path) as tar:\n",
    "    train_stories = get_stories(tar.extractfile(challenge.format('train')))\n",
    "    test_stories = get_stories(tar.extractfile(challenge.format('test')))\n",
    "\n",
    "vocab = set()\n",
    "for story, q, answer in train_stories + test_stories:\n",
    "    vocab |= set(story + q + [answer])\n",
    "vocab = sorted(vocab)\n",
    "\n",
    "# Reserve 0 for masking via pad_sequences\n",
    "vocab_size = len(vocab) + 1\n",
    "story_maxlen = max(map(len, (x for x, _, _ in train_stories + test_stories)))\n",
    "query_maxlen = max(map(len, (x for _, x, _ in train_stories + test_stories)))\n",
    "\n",
    "print('-')\n",
    "print('Vocab size:', vocab_size, 'unique words')\n",
    "print('Story max length:', story_maxlen, 'words')\n",
    "print('Query max length:', query_maxlen, 'words')\n",
    "print('Number of training stories:', len(train_stories))\n",
    "print('Number of test stories:', len(test_stories))\n",
    "print('-')\n",
    "print('Here\\'s what a \"story\" tuple looks like (input, query, answer):')\n",
    "print(train_stories[0])\n",
    "print('-')\n",
    "print('Vectorizing the word sequences...')\n",
    "\n",
    "word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n",
    "inputs_train, queries_train, answers_train = vectorize_stories(train_stories)\n",
    "inputs_test, queries_test, answers_test = vectorize_stories(test_stories)\n",
    "\n",
    "print('-')\n",
    "print('inputs: integer tensor of shape (samples, max_length)')\n",
    "print('inputs_train shape:', inputs_train.shape)\n",
    "print('inputs_test shape:', inputs_test.shape)\n",
    "print('-')\n",
    "print('queries: integer tensor of shape (samples, max_length)')\n",
    "print('queries_train shape:', queries_train.shape)\n",
    "print('queries_test shape:', queries_test.shape)\n",
    "print('-')\n",
    "print('answers: binary (1 or 0) tensor of shape (samples, vocab_size)')\n",
    "print('answers_train shape:', answers_train.shape)\n",
    "print('answers_test shape:', answers_test.shape)\n",
    "print('-')\n",
    "print('Compiling...')\n",
    "\n",
    "# placeholders\n",
    "input_sequence = Input((story_maxlen,))\n",
    "question = Input((query_maxlen,))\n",
    "\n",
    "num_hops=3\n",
    "for i in range(num_hops):\n",
    "    print(i)\n",
    "    # encoders\n",
    "    # embed the input sequence into a sequence of vectors\n",
    "    input_encoder_m = Sequential()\n",
    "    input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
    "                                  output_dim=64))\n",
    "    input_encoder_m.add(Dropout(0.3))\n",
    "    # output: (samples, story_maxlen, embedding_dim)\n",
    "\n",
    "    # embed the input into a sequence of vectors of size query_maxlen\n",
    "    input_encoder_c = Sequential()\n",
    "    input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
    "                                  output_dim=query_maxlen))\n",
    "    input_encoder_c.add(Dropout(0.3))\n",
    "    # output: (samples, story_maxlen, query_maxlen)\n",
    "\n",
    "    # embed the question into a sequence of vectors\n",
    "    question_encoder = Sequential()\n",
    "    question_encoder.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=query_maxlen))\n",
    "\n",
    "    question_encoder.add(Dropout(0.3))\n",
    "    # output: (samples, query_maxlen, embedding_dim)\n",
    "\n",
    "    # encode input sequence and questions (which are indices)\n",
    "    # to sequences of dense vectors\n",
    "    input_encoded_m = input_encoder_m(inputs=input_sequence) # Meaning that \"inputs = input_sequence\"\n",
    "    input_encoded_c = input_encoder_c(input_sequence)\n",
    "    question_encoded = question_encoder(question)\n",
    "    #DEBUG\n",
    "    print(\"input_sequence\", input_sequence.get_shape())\n",
    "    print(\"question\", question.get_shape())\n",
    "    print(\"input_encoded\", input_encoded_m.get_shape())\n",
    "    print(\"question_encoded\", question_encoded.get_shape())\n",
    "    \n",
    "    # compute a 'match' between the first input vector sequence\n",
    "    # and the question vector sequence\n",
    "    # shape: `(samples, story_maxlen, query_maxlen)`\n",
    "    match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "    match = Activation('softmax')(match)\n",
    "\n",
    "    # add the match matrix with the second input vector sequence\n",
    "    response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "    response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)\n",
    "#     print(response.get_shape())\n",
    "    \n",
    "#     question_decoder # IMPLEMENT THIS\n",
    "    input_sequence = response\n",
    "    question = question_encoded\n",
    "    \n",
    "print(question_encoded.get_shape())\n",
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])\n",
    "\n",
    "print(answer.get_shape())\n",
    "\n",
    "\n",
    "# the original paper uses a matrix multiplication for this reduction step.\n",
    "# we choose to use a RNN instead.\n",
    "# answer = LSTM(32, return_sequences=True)(answer)  # (samples, 32)\n",
    "\n",
    "# # one regularization layer -- more would probably be needed.\n",
    "# answer = Dropout(0.3)(answer)\n",
    "answer = LSTM(32)(answer)\n",
    "answer = Dropout(0.3)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
    "\n",
    "#     input_sequence = response\n",
    "\n",
    "    \n",
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "model.fit([inputs_train, queries_train], answers_train,\n",
    "          batch_size=32,\n",
    "          epochs=120,\n",
    "          validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.evaluate(test_stories, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+GXJwhhjjF+WLIwxxvj1/wG6uFkJTQwU5wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "plt.plot(model.history.history['acc'][-40:])\n",
    "plt.plot(model.history.history['val_acc'][-40:])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"2lstm32_.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
